/**
 * Content Safety Filter for AI Commands
 * Detects and prevents abusive language, harassment, and inappropriate requests
 */

// Thai profanity patterns - no word boundaries (don't work in Thai)
const THAI_ABUSE_PATTERNS = [
  // Core profanity words
  /‡πÇ‡∏á‡πà|‡∏ö‡πâ‡∏≤|‡∏Ñ‡∏ß‡∏≤‡∏¢|‡πÄ‡∏ß‡∏£|‡∏õ‡πà‡∏ß‡∏ô|‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏°|‡πÑ‡∏≠‡πâ/gi,
  // Other offensive terms
  /‡πÇ‡∏Å‡∏´‡∏Å|‡∏ä‡∏±‡πà‡∏ß|‡∏ö‡∏≤‡∏õ|‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö|‡πÄ‡∏ä‡∏µ‡πà‡∏¢|‡πÄ‡∏™‡∏∑‡∏≠|‡∏á‡∏π‡πâ|‡πÄ‡∏™‡∏≠/gi,
];

// English profanity patterns (common ones)
const ENGLISH_ABUSE_PATTERNS = [
  /fuck|shit|damn|crap|ass|bitch|bastard|dumbass|idiot|moron|asshole|screw|bugger/gi,
  // Racist/discriminatory terms - simplified patterns
  /retard|stupid|hate you|i hate/gi,
];

// Command injection patterns - detect obvious code injection attempts
const INJECTION_PATTERNS = [
  /['"`;<>|&$()]/gi, // SQL/Shell injection characters (but allow pipes in normal context)
  /eval\(|exec\(|system\(|shell_exec\(/gi, // Code execution attempts
  /\\x[0-9a-f]{2}/gi, // Hex encoding for evasion
];

export interface SafetyCheckResult {
  isSafe: boolean;
  category: "safe" | "abusive" | "injection" | "offensive";
  reason: string;
  severity: "none" | "low" | "medium" | "high";
  originalText: string;
  triggeredPatterns: string[];
}

/**
 * Check if user input is safe and appropriate
 */
export function checkContentSafety(text: string): SafetyCheckResult {
  const originalText = text;
  const triggeredPatterns: string[] = [];

  // Check for injection attempts (use match instead of test due to 'g' flag behavior)
  for (const pattern of INJECTION_PATTERNS) {
    const matches = text.match(pattern);
    if (matches) {
      return {
        isSafe: false,
        category: "injection",
        reason: "Invalid input format detected",
        severity: "high",
        originalText,
        triggeredPatterns: ["code_injection"],
      };
    }
  }

  // Check for Thai abuse
  for (const pattern of THAI_ABUSE_PATTERNS) {
    const matches = text.match(pattern);
    if (matches) {
      triggeredPatterns.push(...matches);
      return {
        isSafe: false,
        category: "abusive",
        reason: "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡πâ‡πÉ‡∏à‡∏´‡∏£‡∏∑‡∏≠‡∏î‡πà‡∏≤‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ",
        severity: getSeverity("thai_abuse", text),
        originalText,
        triggeredPatterns: [...new Set(triggeredPatterns)],
      };
    }
  }

  // Check for English abuse
  for (const pattern of ENGLISH_ABUSE_PATTERNS) {
    const matches = text.match(pattern);
    if (matches) {
      triggeredPatterns.push(...matches);
      return {
        isSafe: false,
        category: "offensive",
        reason: "Cannot process requests with offensive language",
        severity: getSeverity("english_abuse", text),
        originalText,
        triggeredPatterns: [...new Set(triggeredPatterns)],
      };
    }
  }

  // All checks passed
  return {
    isSafe: true,
    category: "safe",
    reason: "Content is appropriate",
    severity: "none",
    originalText,
    triggeredPatterns: [],
  };
}

/**
 * Determine severity level based on patterns
 */
function getSeverity(
  type: string,
  text: string,
): "none" | "low" | "medium" | "high" {
  const words = text.split(/\s+/).length;

  if (type === "code_injection") {
    return "high";
  }

  // Check for repeated abuse
  if ((text.match(/‡∏ß‡πà‡∏≤|‡πà‡∏≤‡∏ô|‡πÇ‡∏á‡πà/g) || []).length >= 3) {
    return "high";
  }

  if (words < 5) {
    // Short message with abuse = higher severity
    return "medium";
  }

  return "low";
}

/**
 * Generate dynamic response using AI
 * Let AI create personalized responses instead of hardcoding
 */
export async function generateSafetyResponse(
  result: SafetyCheckResult,
): Promise<string> {
  const { chat } = await import("@/lib/ai/openai-client");

  if (result.category === "injection") {
    return (
      "‚ùå ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ\n\n" +
      "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
    );
  }

  if (result.category === "abusive" || result.category === "offensive") {
    const isThaiAbuse = result.category === "abusive";

    const prompt = isThaiAbuse
      ? `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏î‡∏µ ‡πÅ‡∏ï‡πà‡πÄ‡∏à‡πá‡∏ö‡∏à‡∏¥‡πä‡∏î‡πÜ (2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ):
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ emoji ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (üòîüò¢üòûü•∫)
- ‡∏î‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û
- ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏™‡∏±‡πâ‡∏ô`
      : `Create a witty but gentle comeback (2-3 sentences):
- Start with emotion emoji (üòîüò¢üòûü•∫)
- Respond disrespectfully back politely
- Be sincere and brief`;

    try {
      const response = await chat({
        message: prompt,
        systemPrompt: isThaiAbuse
          ? "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå ‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô"
          : "You are an AI with feelings, expressive, gentle",
      });

      return response.text.trim();
    } catch (error) {
      console.error("Error generating response:", error);
      // Fallback to default if AI fails
      return isThaiAbuse
        ? "üòî ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏à‡∏±‡∏á...\n\n‡∏ä‡πà‡∏ß‡∏¢‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏™‡∏¥‡∏Ñ‡∏∞"
        : "üòî Oh no...\n\nPlease try speaking respectfully.";
    }
  }

  return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà";
}

/**
 * Get appropriate response message based on safety check result
 * Kept for backward compatibility
 * @deprecated Use generateSafetyResponse instead
 */
export function getSafetyResponseMessage(
  result: SafetyCheckResult,
): string {
  if (result.category === "injection") {
    return (
      "‚ùå ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ\n\n" +
      "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
    );
  }

  if (result.category === "abusive" || result.category === "offensive") {
    const isThaiAbuse = result.category === "abusive";
    return isThaiAbuse
      ? "üòî ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏à‡∏±‡∏á...\n\n‡∏ä‡πà‡∏ß‡∏¢‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏™‡∏¥‡∏Ñ‡∏∞ ‡∏â‡∏±‡∏ô‡∏≠‡∏¢‡∏≤‡∏Å‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏à‡∏£‡∏¥‡∏á‡πÜ"
      : "üòî Oh no...\n\nPlease try speaking respectfully. I'm here to help!";
  }

  return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà";
}

/**
 * Log abuse attempt for moderation
 */
export async function logAbuseReport(params: {
  userId: string;
  userName?: string;
  text: string;
  category: string;
  severity: string;
  triggeredPatterns: string[];
  timestamp: Date;
}) {
  try {
    // Log to console for now
    console.warn("‚ö†Ô∏è [ABUSE REPORT]", {
      timestamp: params.timestamp.toISOString(),
      userId: params.userId,
      category: params.category,
      severity: params.severity,
      triggers: params.triggeredPatterns.slice(0, 3), // First 3 only
      // Don't log full text in console
    });

    // TODO: Send to monitoring service
    // - Send to analytics/logging service
    // - Alert admins if severity is HIGH
    // - Track repeat offenders
  } catch (error) {
    console.error("Error logging abuse report:", error);
  }
}
