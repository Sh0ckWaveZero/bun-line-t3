/**
 * Content Safety Filter for AI Commands
 * Detects and prevents abusive language, harassment, and inappropriate requests
 */

// Thai profanity patterns - no word boundaries (don't work in Thai)
const THAI_ABUSE_PATTERNS = [
  // Core profanity words
  /‡πÇ‡∏á‡πà|‡∏ö‡πâ‡∏≤|‡∏Ñ‡∏ß‡∏≤‡∏¢|‡πÄ‡∏ß‡∏£|‡∏õ‡πà‡∏ß‡∏ô|‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏°|‡πÑ‡∏≠‡πâ/gi,
  // Other offensive terms
  /‡πÇ‡∏Å‡∏´‡∏Å|‡∏ä‡∏±‡πà‡∏ß|‡∏ö‡∏≤‡∏õ|‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö|‡πÄ‡∏ä‡∏µ‡πà‡∏¢|‡πÄ‡∏™‡∏∑‡∏≠|‡∏á‡∏π‡πâ|‡πÄ‡∏™‡∏≠/gi,
];

// English profanity patterns (common ones)
const ENGLISH_ABUSE_PATTERNS = [
  /fuck|shit|damn|crap|ass|bitch|bastard|dumbass|idiot|moron|asshole|screw|bugger/gi,
  // Racist/discriminatory terms - simplified patterns
  /retard|stupid|hate you|i hate/gi,
];

// Command injection patterns - detect obvious code injection attempts
const INJECTION_PATTERNS = [
  /['"`;<>|&$()]/gi, // SQL/Shell injection characters (but allow pipes in normal context)
  /eval\(|exec\(|system\(|shell_exec\(/gi, // Code execution attempts
  /\\x[0-9a-f]{2}/gi, // Hex encoding for evasion
];

export interface SafetyCheckResult {
  isSafe: boolean;
  category: "safe" | "abusive" | "injection" | "offensive";
  reason: string;
  severity: "none" | "low" | "medium" | "high";
  originalText: string;
  triggeredPatterns: string[];
}

/**
 * Check if user input is safe and appropriate
 */
export function checkContentSafety(text: string): SafetyCheckResult {
  const originalText = text;
  const triggeredPatterns: string[] = [];

  // Check for injection attempts (use match instead of test due to 'g' flag behavior)
  for (const pattern of INJECTION_PATTERNS) {
    const matches = text.match(pattern);
    if (matches) {
      return {
        isSafe: false,
        category: "injection",
        reason: "Invalid input format detected",
        severity: "high",
        originalText,
        triggeredPatterns: ["code_injection"],
      };
    }
  }

  // Check for Thai abuse
  for (const pattern of THAI_ABUSE_PATTERNS) {
    const matches = text.match(pattern);
    if (matches) {
      triggeredPatterns.push(...matches);
      return {
        isSafe: false,
        category: "abusive",
        reason: "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°ÁÑ°‡πÉ‡∏à‡∏´‡∏£‡∏∑‡∏≠‡∏î‡πà‡∏≤‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ",
        severity: getSeverity("thai_abuse", text),
        originalText,
        triggeredPatterns: [...new Set(triggeredPatterns)],
      };
    }
  }

  // Check for English abuse
  for (const pattern of ENGLISH_ABUSE_PATTERNS) {
    const matches = text.match(pattern);
    if (matches) {
      triggeredPatterns.push(...matches);
      return {
        isSafe: false,
        category: "offensive",
        reason: "Cannot process requests with offensive language",
        severity: getSeverity("english_abuse", text),
        originalText,
        triggeredPatterns: [...new Set(triggeredPatterns)],
      };
    }
  }

  // All checks passed
  return {
    isSafe: true,
    category: "safe",
    reason: "Content is appropriate",
    severity: "none",
    originalText,
    triggeredPatterns: [],
  };
}

/**
 * Determine severity level based on patterns
 */
function getSeverity(
  type: string,
  text: string,
): "none" | "low" | "medium" | "high" {
  const words = text.split(/\s+/).length;

  if (type === "code_injection") {
    return "high";
  }

  // Check for repeated abuse
  if ((text.match(/‡∏ß‡πà‡∏≤|‡πà‡∏≤‡∏ô|‡πÇ‡∏á‡πà/g) || []).length >= 3) {
    return "high";
  }

  if (words < 5) {
    // Short message with abuse = higher severity
    return "medium";
  }

  return "low";
}

/**
 * Generate dynamic response using AI
 * Let AI create personalized responses instead of hardcoding
 */
export async function generateSafetyResponse(
  result: SafetyCheckResult,
): Promise<string> {
  const { chat } = await import("@/lib/ai/openai-client");

  if (result.category === "injection") {
    return (
      "‚ùå ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ\n\n" +
      "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
    );
  }

  if (result.category === "abusive" || result.category === "offensive") {
    const isThaiAbuse = result.category === "abusive";
    const language = isThaiAbuse ? "Thai" : "English";

    const prompt = isThaiAbuse
      ? `‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏ô‡∏û‡∏π‡∏î‡∏à‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏ß‡∏£:
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ emoji ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (üòîüò¢üòûü•∫)
- ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏à
- ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÇ‡∏Å‡∏£‡∏ò
- ‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô‡πÉ‡∏´‡πâ‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏Å‡∏ß‡πà‡∏≤
- ‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏à (2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)

‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:`
      : `You are an AI assistant that feels hurt because someone used offensive language. Create a message that shows genuine sadness, is respectful and constructive.

The message should:
- Start with an emotion emoji (üòîüò¢üòûü•∫)
- Show sincere effort to help
- Feel hurt but not angry
- Invite respectful communication
- Be brief and genuine (2-3 sentences)

Create a new unique message. Only the message text itself:`;

    try {
      const response = await chat({
        message: prompt,
        systemPrompt: isThaiAbuse
          ? "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô"
          : "You are an AI with feelings and a gentle personality",
      });

      return response.text.trim();
    } catch (error) {
      console.error("Error generating response:", error);
      // Fallback to default if AI fails
      return isThaiAbuse
        ? "üòî ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏à‡∏±‡∏á...\n\n‡∏ä‡πà‡∏ß‡∏¢‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏™‡∏¥‡∏Ñ‡∏∞"
        : "üòî Oh no...\n\nPlease try speaking respectfully.";
    }
  }

  return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà";
}

/**
 * Get appropriate response message based on safety check result
 * Kept for backward compatibility
 * @deprecated Use generateSafetyResponse instead
 */
export function getSafetyResponseMessage(
  result: SafetyCheckResult,
): string {
  if (result.category === "injection") {
    return (
      "‚ùå ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ\n\n" +
      "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
    );
  }

  if (result.category === "abusive" || result.category === "offensive") {
    const isThaiAbuse = result.category === "abusive";
    return isThaiAbuse
      ? "üòî ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏à‡∏±‡∏á...\n\n‡∏ä‡πà‡∏ß‡∏¢‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏™‡∏¥‡∏Ñ‡∏∞ ‡∏â‡∏±‡∏ô‡∏≠‡∏¢‡∏≤‡∏Å‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏à‡∏£‡∏¥‡∏á‡πÜ"
      : "üòî Oh no...\n\nPlease try speaking respectfully. I'm here to help!";
  }

  return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà";
}

/**
 * Log abuse attempt for moderation
 */
export async function logAbuseReport(params: {
  userId: string;
  userName?: string;
  text: string;
  category: string;
  severity: string;
  triggeredPatterns: string[];
  timestamp: Date;
}) {
  try {
    // Log to console for now
    console.warn("‚ö†Ô∏è [ABUSE REPORT]", {
      timestamp: params.timestamp.toISOString(),
      userId: params.userId,
      category: params.category,
      severity: params.severity,
      triggers: params.triggeredPatterns.slice(0, 3), // First 3 only
      // Don't log full text in console
    });

    // TODO: Send to monitoring service
    // - Send to analytics/logging service
    // - Alert admins if severity is HIGH
    // - Track repeat offenders
  } catch (error) {
    console.error("Error logging abuse report:", error);
  }
}
